## The bias-variance debate {#sec:biasVariance} 
Assume there is a set of given instances, $X$ (m rows and n columns), and we are asked to optimize a model $M(X, \theta)$ to estimate $Y$ (m rows). Let us call each instance x and its corresponding desired output as y. In reality, y is the outcome of a system working with inputs x, and some noise, $y=f(x)+\epsilon$, where f(.) is not known and \epsilon is noise. For example, if x represents characteristics of people and y is whether or not they gonna have heart-attack after their 50s, f(x) is how body is impacted by those characteristics and if it leads to a heart-attack, which is not really known. What we try to do is to estimate this f(x), given some examples and some assumptions of the shape of f. 

After optimization, what we would get is $Y=M(X, \hat{\theta})+\epsilon$, where $\epsilon$ has $m$ rows and indicates the error from $Y$. If $\epsilon$ is very small then that means $M(X, \hat{\theta})$ is an accurate estimation of $Y$. If the model M is a complex, flexible, equation then it will be able to fit any complex behavior of $Y$ as function of $X$, including all fluctuations. In that case, the outputs of the model will be very very similar to the values of $Y$ (non-biased), however, it will have lots of fluctuations, which leads to a high variance (large fluctuations usually leads to large variance). If the model is not complex though, the gap between the output of the model and $Y$ might be large (bias), however, it will not fit all fluctuations in the $Y$ which leads to smaller variance. That is why it is said a complex model has a large variance and small bias, and vice versa.

## Regularization

Let's assume that we are fitting a model $M(X, \theta)$ to the instances $X$, given labels $Y$, using an optimization algorithm and an evaluation metric, $E(M(X, \theta), Y)$, which provides a scaler describing how dissimilar is $M(X, \theta)$ to the corresponding $Y$. 

\begin{equation}
min_{\theta}  ~E(M(X, \theta), Y) (\#eq:optimizationOrginal)
\end{equation}

Depending on the definition of $E$ and $M$, this problem might not have a unique solution. Hence, the optimization algorithm should be informed which solution is more acceptable so that it converges to what it supposed to. Here comes regularization. It provides another constraint, formulated into the objective function for convenience (see section ???? to see how is this possible), to make the solution unique, as follows: 

\begin{equation}
min_{\theta}  ~E(M(X, \theta), Y) + \alpha R(\theta) (\#eq:optimizationregularized)
\end{equation}

where $R(\theta)$ is the regularization term and $\alpha$ is the regularization weight. 

### Famous types
As the idea is a "simpler" model has a better chance to generalize better (see Section \@ref(sec:biasVariance)), the regularization term is defined in a way that it simplifies the model. Two of most frequently used regularization terms are called $L_1$ (aka LASSO) and $L_2$ (special case of Tikhonov), defined by $||\theta||_1=\sum_i |\theta_i|$ and $||\theta||_2=\sum_i \theta_i^2$, respectively. 

### More details

See [wekipedia](https://en.wikipedia.org/wiki/Regularization_(mathematics)) for more information on this.


Another useful regularization term is the $L_0$ which counts the number of non-zero 




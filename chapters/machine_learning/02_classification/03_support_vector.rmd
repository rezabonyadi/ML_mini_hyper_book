## Support vector machines
***Category Intuitive***
Consider a binary classification problem and assume we want to use a hyperplane (linear model) to separate the classes. There might be many hyperplanes which separate the classes, all of which would result in the same mis-classification error. This encourages design of constraints which narrow down acceptable hyperplanes. One reasonable constraint is to pick the hyperplane which has maximum distance from the instances from both classes. This idea forms the bases for the support vector machine (SVM). 


```{r svm1, echo = FALSE, out.width = '50%', fig.cap = 'The blue line has the same distance from the instances in each class, which is the idea behind SVM.'}
knitr::include_graphics('images/classification/svm_1.PNG')
```
It is expected that SVM works better on the unseen instances. This, however, is not always true. 

### More details
***Category Deep***


### Kernel trick
***Category Intuitive, Deep***


### Some improvements


Also talk about dimensionality reduction

### Implementation
***Category Code***

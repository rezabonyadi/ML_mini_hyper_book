<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Machine learning, statistics, and optimization: A collection of intuitions</title>
  <meta name="description" content="." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Machine learning, statistics, and optimization: A collection of intuitions" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="." />
  <meta name="github-repo" content="rezabontadi/machine-learning-hyper-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine learning, statistics, and optimization: A collection of intuitions" />
  
  <meta name="twitter:description" content="." />
  

<meta name="author" content="Reza Bonyadi, Ph.D." />


<meta name="date" content="2020-03-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="introduction.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Machine learning</b></span></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#sec:supervisedvsunsupervised"><i class="fa fa-check"></i><b>1.1</b> Supervised and unsupervised learning</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#sec:supervisedmodels"><i class="fa fa-check"></i><b>1.2</b> Supervised models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>2</b> Classification</a><ul>
<li class="chapter" data-level="2.1" data-path="classification.html"><a href="classification.html#generative-vs.discriminative-classifiers"><i class="fa fa-check"></i><b>2.1</b> Generative vs.Â discriminative classifiers</a></li>
<li class="chapter" data-level="2.2" data-path="classification.html"><a href="classification.html#loss-function-for-classification"><i class="fa fa-check"></i><b>2.2</b> 0/1 loss function for classification</a><ul>
<li class="chapter" data-level="2.2.1" data-path="classification.html"><a href="classification.html#improvements"><i class="fa fa-check"></i><b>2.2.1</b> Improvements</a></li>
<li class="chapter" data-level="2.2.2" data-path="classification.html"><a href="classification.html#pros-and-cons"><i class="fa fa-check"></i><b>2.2.2</b> Pros and cons</a></li>
<li class="chapter" data-level="2.2.3" data-path="classification.html"><a href="classification.html#implementation"><i class="fa fa-check"></i><b>2.2.3</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="classification.html"><a href="classification.html#logistic-regression"><i class="fa fa-check"></i><b>2.3</b> Logistic regression</a><ul>
<li class="chapter" data-level="2.3.1" data-path="classification.html"><a href="classification.html#interpretability"><i class="fa fa-check"></i><b>2.3.1</b> Interpretability</a></li>
<li class="chapter" data-level="2.3.2" data-path="classification.html"><a href="classification.html#pros-and-cons-1"><i class="fa fa-check"></i><b>2.3.2</b> Pros and cons</a></li>
<li class="chapter" data-level="2.3.3" data-path="classification.html"><a href="classification.html#implementation-1"><i class="fa fa-check"></i><b>2.3.3</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="classification.html"><a href="classification.html#bayes-classifier"><i class="fa fa-check"></i><b>2.4</b> Bayes classifier</a><ul>
<li class="chapter" data-level="2.4.1" data-path="classification.html"><a href="classification.html#pros-and-cons-2"><i class="fa fa-check"></i><b>2.4.1</b> Pros and cons</a></li>
<li class="chapter" data-level="2.4.2" data-path="classification.html"><a href="classification.html#implementation-2"><i class="fa fa-check"></i><b>2.4.2</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="classification.html"><a href="classification.html#support-vector-machines"><i class="fa fa-check"></i><b>2.5</b> Support vector machines</a><ul>
<li class="chapter" data-level="2.5.1" data-path="classification.html"><a href="classification.html#interpretability-1"><i class="fa fa-check"></i><b>2.5.1</b> Interpretability</a></li>
<li class="chapter" data-level="2.5.2" data-path="classification.html"><a href="classification.html#improvements-1"><i class="fa fa-check"></i><b>2.5.2</b> Improvements</a></li>
<li class="chapter" data-level="2.5.3" data-path="classification.html"><a href="classification.html#implementation-3"><i class="fa fa-check"></i><b>2.5.3</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="classification.html"><a href="classification.html#sec:descisiontree"><i class="fa fa-check"></i><b>2.6</b> Decision tree</a></li>
<li class="chapter" data-level="2.7" data-path="classification.html"><a href="classification.html#sec:KNN"><i class="fa fa-check"></i><b>2.7</b> K-nearest neighbor</a><ul>
<li class="chapter" data-level="2.7.1" data-path="classification.html"><a href="classification.html#improvements-2"><i class="fa fa-check"></i><b>2.7.1</b> Improvements</a></li>
<li class="chapter" data-level="2.7.2" data-path="classification.html"><a href="classification.html#pros-and-cons-3"><i class="fa fa-check"></i><b>2.7.2</b> Pros and cons</a></li>
<li class="chapter" data-level="2.7.3" data-path="classification.html"><a href="classification.html#more-details"><i class="fa fa-check"></i><b>2.7.3</b> More details</a></li>
<li class="chapter" data-level="2.7.4" data-path="classification.html"><a href="classification.html#implementation-4"><i class="fa fa-check"></i><b>2.7.4</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="classification.html"><a href="classification.html#gaussianprocessclassifier"><i class="fa fa-check"></i><b>2.8</b> Gaussian process classifier</a></li>
<li class="chapter" data-level="2.9" data-path="classification.html"><a href="classification.html#general-additive-model"><i class="fa fa-check"></i><b>2.9</b> General additive model</a></li>
<li class="chapter" data-level="2.10" data-path="classification.html"><a href="classification.html#turning-binary-classifiers-to-multi-class"><i class="fa fa-check"></i><b>2.10</b> Turning binary classifiers to multi-class</a></li>
<li class="chapter" data-level="2.11" data-path="classification.html"><a href="classification.html#performance-measures-and-evaluation"><i class="fa fa-check"></i><b>2.11</b> Performance measures and evaluation</a><ul>
<li class="chapter" data-level="2.11.1" data-path="classification.html"><a href="classification.html#signal-detection"><i class="fa fa-check"></i><b>2.11.1</b> Signal detection</a></li>
<li class="chapter" data-level="2.11.2" data-path="classification.html"><a href="classification.html#receiver-operating-characteristic-roc-and-area-under-the-curve-auc"><i class="fa fa-check"></i><b>2.11.2</b> Receiver operating characteristic (ROC) and Area under the curve (AUC)</a></li>
<li class="chapter" data-level="2.11.3" data-path="classification.html"><a href="classification.html#confusion-matrix"><i class="fa fa-check"></i><b>2.11.3</b> Confusion matrix</a></li>
<li class="chapter" data-level="2.11.4" data-path="classification.html"><a href="classification.html#benchmarking"><i class="fa fa-check"></i><b>2.11.4</b> Benchmarking</a></li>
<li class="chapter" data-level="2.11.5" data-path="classification.html"><a href="classification.html#stratified-sampling"><i class="fa fa-check"></i><b>2.11.5</b> Stratified sampling</a></li>
<li class="chapter" data-level="2.11.6" data-path="classification.html"><a href="classification.html#cross-validation-and-random-permutation"><i class="fa fa-check"></i><b>2.11.6</b> Cross validation and random permutation</a></li>
<li class="chapter" data-level="2.11.7" data-path="classification.html"><a href="classification.html#imbalance-data-sets"><i class="fa fa-check"></i><b>2.11.7</b> Imbalance data sets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>3</b> Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="regression.html"><a href="regression.html#linear-regression"><i class="fa fa-check"></i><b>3.1</b> Linear regression</a></li>
<li class="chapter" data-level="3.2" data-path="regression.html"><a href="regression.html#multivariate-adaptive-regression-spline"><i class="fa fa-check"></i><b>3.2</b> Multivariate Adaptive Regression Spline</a></li>
<li class="chapter" data-level="3.3" data-path="regression.html"><a href="regression.html#generalized-additive-model"><i class="fa fa-check"></i><b>3.3</b> Generalized additive model</a></li>
<li class="chapter" data-level="3.4" data-path="regression.html"><a href="regression.html#decision-tree-for-regression"><i class="fa fa-check"></i><b>3.4</b> Decision tree for regression</a></li>
<li class="chapter" data-level="3.5" data-path="regression.html"><a href="regression.html#performance-measures"><i class="fa fa-check"></i><b>3.5</b> Performance measures</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html"><i class="fa fa-check"></i><b>4</b> Dimensionality reduction</a><ul>
<li class="chapter" data-level="4.1" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#more-details-1"><i class="fa fa-check"></i><b>4.1</b> More details</a></li>
<li class="chapter" data-level="4.2" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#principal-component-analysis"><i class="fa fa-check"></i><b>4.2</b> Principal component analysis</a></li>
<li class="chapter" data-level="4.3" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#t-sne"><i class="fa fa-check"></i><b>4.3</b> T-SNE</a></li>
<li class="chapter" data-level="4.4" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#independent-component-analysis"><i class="fa fa-check"></i><b>4.4</b> Independent component analysis</a></li>
<li class="chapter" data-level="4.5" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#partial-least-square"><i class="fa fa-check"></i><b>4.5</b> Partial least square</a></li>
<li class="chapter" data-level="4.6" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>4.6</b> Linear discriminant analysis</a></li>
<li class="chapter" data-level="4.7" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#svm-dimensionality-reduction"><i class="fa fa-check"></i><b>4.7</b> SVM dimensionality reduction</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sec-metricslearning.html"><a href="sec-metricslearning.html"><i class="fa fa-check"></i><b>5</b> Metrics learning</a><ul>
<li class="chapter" data-level="5.1" data-path="sec-metricslearning.html"><a href="sec-metricslearning.html#large-margin-nearest-neighbor"><i class="fa fa-check"></i><b>5.1</b> Large margin nearest neighbor</a></li>
<li class="chapter" data-level="5.2" data-path="sec-metricslearning.html"><a href="sec-metricslearning.html#metric-learning-for-kernel-regression"><i class="fa fa-check"></i><b>5.2</b> Metric learning for kernel regression</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>6</b> Neural networks</a><ul>
<li class="chapter" data-level="6.1" data-path="neural-networks.html"><a href="neural-networks.html#multi-layer-perceptron"><i class="fa fa-check"></i><b>6.1</b> Multi-layer perceptron</a></li>
<li class="chapter" data-level="6.2" data-path="neural-networks.html"><a href="neural-networks.html#mixed-density-networks"><i class="fa fa-check"></i><b>6.2</b> Mixed density networks</a></li>
<li class="chapter" data-level="6.3" data-path="neural-networks.html"><a href="neural-networks.html#convolutional-neural-networks"><i class="fa fa-check"></i><b>6.3</b> Convolutional neural networks</a></li>
<li class="chapter" data-level="6.4" data-path="neural-networks.html"><a href="neural-networks.html#autoencoders"><i class="fa fa-check"></i><b>6.4</b> Autoencoders</a></li>
<li class="chapter" data-level="6.5" data-path="neural-networks.html"><a href="neural-networks.html#generative-adversial-neural-network"><i class="fa fa-check"></i><b>6.5</b> Generative adversial neural network</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>7</b> Bayesian inference</a></li>
<li class="chapter" data-level="8" data-path="ensemble-techniques.html"><a href="ensemble-techniques.html"><i class="fa fa-check"></i><b>8</b> Ensemble techniques</a><ul>
<li class="chapter" data-level="8.1" data-path="ensemble-techniques.html"><a href="ensemble-techniques.html#random-forest"><i class="fa fa-check"></i><b>8.1</b> Random forest</a></li>
<li class="chapter" data-level="8.2" data-path="ensemble-techniques.html"><a href="ensemble-techniques.html#gradient-boosting"><i class="fa fa-check"></i><b>8.2</b> Gradient boosting</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reinforcement-learning.html"><a href="reinforcement-learning.html"><i class="fa fa-check"></i><b>9</b> Reinforcement learning</a><ul>
<li class="chapter" data-level="9.1" data-path="reinforcement-learning.html"><a href="reinforcement-learning.html#q-learning"><i class="fa fa-check"></i><b>9.1</b> Q-learning</a></li>
<li class="chapter" data-level="9.2" data-path="reinforcement-learning.html"><a href="reinforcement-learning.html#curiosity"><i class="fa fa-check"></i><b>9.2</b> Curiosity</a><ul>
<li class="chapter" data-level="9.2.1" data-path="reinforcement-learning.html"><a href="reinforcement-learning.html#implementation-idea"><i class="fa fa-check"></i><b>9.2.1</b> Implementation idea</a></li>
<li class="chapter" data-level="9.2.2" data-path="reinforcement-learning.html"><a href="reinforcement-learning.html#what-does-it-solve"><i class="fa fa-check"></i><b>9.2.2</b> What does it solve?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bagging-and-boosting.html"><a href="bagging-and-boosting.html"><i class="fa fa-check"></i><b>10</b> Bagging and boosting</a><ul>
<li class="chapter" data-level="10.1" data-path="bagging-and-boosting.html"><a href="bagging-and-boosting.html#extreme-boosted-tree"><i class="fa fa-check"></i><b>10.1</b> Extreme boosted tree</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="anomaly-detection.html"><a href="anomaly-detection.html"><i class="fa fa-check"></i><b>11</b> Anomaly detection</a><ul>
<li class="chapter" data-level="11.1" data-path="anomaly-detection.html"><a href="anomaly-detection.html#autoencoder"><i class="fa fa-check"></i><b>11.1</b> Autoencoder</a></li>
<li class="chapter" data-level="11.2" data-path="anomaly-detection.html"><a href="anomaly-detection.html#one-class-svm"><i class="fa fa-check"></i><b>11.2</b> One class SVM</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="sec-preprocessing.html"><a href="sec-preprocessing.html"><i class="fa fa-check"></i><b>12</b> Preprocessing</a><ul>
<li class="chapter" data-level="12.1" data-path="sec-preprocessing.html"><a href="sec-preprocessing.html#normalization-and-standardization"><i class="fa fa-check"></i><b>12.1</b> Normalization and standardization</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="sec-signalProcessing.html"><a href="sec-signalProcessing.html"><i class="fa fa-check"></i><b>13</b> Signal processing</a></li>
<li class="chapter" data-level="14" data-path="sec-causal-models.html"><a href="sec-causal-models.html"><i class="fa fa-check"></i><b>14</b> Causal models</a><ul>
<li class="chapter" data-level="14.1" data-path="sec-causal-models.html"><a href="sec-causal-models.html#graphical-models"><i class="fa fa-check"></i><b>14.1</b> Graphical models</a></li>
<li class="chapter" data-level="14.2" data-path="sec-causal-models.html"><a href="sec-causal-models.html#bayesian-networks"><i class="fa fa-check"></i><b>14.2</b> Bayesian networks</a><ul>
<li class="chapter" data-level="14.2.1" data-path="sec-causal-models.html"><a href="sec-causal-models.html#improvements-3"><i class="fa fa-check"></i><b>14.2.1</b> Improvements</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="sec-causal-models.html"><a href="sec-causal-models.html#markov-random-field"><i class="fa fa-check"></i><b>14.3</b> Markov random field</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html"><i class="fa fa-check"></i><b>15</b> Important considerations in machine learning methods</a><ul>
<li class="chapter" data-level="15.1" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html#sec:biasVariance"><i class="fa fa-check"></i><b>15.1</b> The bias-variance debate</a></li>
<li class="chapter" data-level="15.2" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html#sec:regularization"><i class="fa fa-check"></i><b>15.2</b> Regularization</a><ul>
<li class="chapter" data-level="15.2.1" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html#famous-types"><i class="fa fa-check"></i><b>15.2.1</b> Famous types</a></li>
<li class="chapter" data-level="15.2.2" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html#more-details-2"><i class="fa fa-check"></i><b>15.2.2</b> More details</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html#raw-data-vs-characterized-data-features"><i class="fa fa-check"></i><b>15.3</b> Raw data vs characterized data (features)</a></li>
<li class="chapter" data-level="15.4" data-path="important-considerations-in-machine-learning-methods.html"><a href="important-considerations-in-machine-learning-methods.html#variable-importance-and-insights-considerations"><i class="fa fa-check"></i><b>15.4</b> Variable importance and insights considerations</a></li>
</ul></li>
<li class="part"><span><b>II Optimziation</b></span></li>
<li class="chapter" data-level="16" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>16</b> Introduction</a><ul>
<li class="chapter" data-level="16.1" data-path="introduction-1.html"><a href="introduction-1.html#derivative-free-vs-with-derivative-optimization-methods"><i class="fa fa-check"></i><b>16.1</b> Derivative-free vs with derivative optimization methods</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="optimization-problems.html"><a href="optimization-problems.html"><i class="fa fa-check"></i><b>17</b> Optimization problems</a><ul>
<li class="chapter" data-level="17.1" data-path="optimization-problems.html"><a href="optimization-problems.html#single-and-multi-objective"><i class="fa fa-check"></i><b>17.1</b> Single and Multi objective</a></li>
<li class="chapter" data-level="17.2" data-path="optimization-problems.html"><a href="optimization-problems.html#constrains-in-problems"><i class="fa fa-check"></i><b>17.2</b> Constrains in problems</a></li>
<li class="chapter" data-level="17.3" data-path="optimization-problems.html"><a href="optimization-problems.html#dynamic-optimization-problems"><i class="fa fa-check"></i><b>17.3</b> Dynamic optimization problems</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="use-of-derivative-in-optimization.html"><a href="use-of-derivative-in-optimization.html"><i class="fa fa-check"></i><b>18</b> Use of derivative in optimization</a></li>
<li class="chapter" data-level="19" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html"><i class="fa fa-check"></i><b>19</b> Derivative-free algorithms</a><ul>
<li class="chapter" data-level="19.1" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html#finite-difference"><i class="fa fa-check"></i><b>19.1</b> Finite difference</a></li>
<li class="chapter" data-level="19.2" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html#population-based-optimization"><i class="fa fa-check"></i><b>19.2</b> Population-based optimization</a><ul>
<li class="chapter" data-level="19.2.1" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html#genetic-algorithm"><i class="fa fa-check"></i><b>19.2.1</b> Genetic algorithm</a></li>
<li class="chapter" data-level="19.2.2" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html#evolutionary-strategy"><i class="fa fa-check"></i><b>19.2.2</b> Evolutionary strategy</a></li>
<li class="chapter" data-level="19.2.3" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html#covariance-matrix-adaptation"><i class="fa fa-check"></i><b>19.2.3</b> Covariance matrix adaptation</a></li>
<li class="chapter" data-level="19.2.4" data-path="derivative-free-algorithms.html"><a href="derivative-free-algorithms.html#particle-swarm-optimization"><i class="fa fa-check"></i><b>19.2.4</b> Particle swarm optimization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="what-are-constraints.html"><a href="what-are-constraints.html"><i class="fa fa-check"></i><b>20</b> What are Constraints</a><ul>
<li class="chapter" data-level="20.1" data-path="what-are-constraints.html"><a href="what-are-constraints.html#how-to-deal-with-constraints"><i class="fa fa-check"></i><b>20.1</b> How to deal with constraints</a><ul>
<li class="chapter" data-level="20.1.1" data-path="what-are-constraints.html"><a href="what-are-constraints.html#sec:lagrangian"><i class="fa fa-check"></i><b>20.1.1</b> Lagrangian</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="famous-forms-of-optimization-problems.html"><a href="famous-forms-of-optimization-problems.html"><i class="fa fa-check"></i><b>21</b> Famous forms of optimization problems</a><ul>
<li class="chapter" data-level="21.1" data-path="famous-forms-of-optimization-problems.html"><a href="famous-forms-of-optimization-problems.html#linear-program"><i class="fa fa-check"></i><b>21.1</b> Linear program</a></li>
<li class="chapter" data-level="21.2" data-path="famous-forms-of-optimization-problems.html"><a href="famous-forms-of-optimization-problems.html#quadratic-objective-with-linear-constraints"><i class="fa fa-check"></i><b>21.2</b> Quadratic objective with linear constraints</a></li>
<li class="chapter" data-level="21.3" data-path="famous-forms-of-optimization-problems.html"><a href="famous-forms-of-optimization-problems.html#quadratic-objective-and-constraints"><i class="fa fa-check"></i><b>21.3</b> Quadratic objective and constraints</a></li>
</ul></li>
<li class="part"><span><b>III Statistics</b></span></li>
<li class="chapter" data-level="22" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>22</b> Introduction</a></li>
<li class="chapter" data-level="23" data-path="basics-statistics.html"><a href="basics-statistics.html"><i class="fa fa-check"></i><b>23</b> Basics statistics</a><ul>
<li class="chapter" data-level="23.1" data-path="basics-statistics.html"><a href="basics-statistics.html#correlation"><i class="fa fa-check"></i><b>23.1</b> Correlation</a></li>
<li class="chapter" data-level="23.2" data-path="basics-statistics.html"><a href="basics-statistics.html#moments"><i class="fa fa-check"></i><b>23.2</b> Moments</a></li>
<li class="chapter" data-level="23.3" data-path="basics-statistics.html"><a href="basics-statistics.html#covariance-matrix"><i class="fa fa-check"></i><b>23.3</b> Covariance matrix</a></li>
<li class="chapter" data-level="23.4" data-path="basics-statistics.html"><a href="basics-statistics.html#matrix-decomposition"><i class="fa fa-check"></i><b>23.4</b> Matrix decomposition</a><ul>
<li class="chapter" data-level="23.4.1" data-path="basics-statistics.html"><a href="basics-statistics.html#eigen-decomposition"><i class="fa fa-check"></i><b>23.4.1</b> Eigen decomposition</a></li>
<li class="chapter" data-level="23.4.2" data-path="basics-statistics.html"><a href="basics-statistics.html#singular-value-decomposition"><i class="fa fa-check"></i><b>23.4.2</b> Singular value decomposition</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="basics-statistics.html"><a href="basics-statistics.html#distributions"><i class="fa fa-check"></i><b>23.5</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="statistical-analysis.html"><a href="statistical-analysis.html"><i class="fa fa-check"></i><b>24</b> Statistical analysis</a><ul>
<li class="chapter" data-level="24.1" data-path="statistical-analysis.html"><a href="statistical-analysis.html#statistical-tests"><i class="fa fa-check"></i><b>24.1</b> Statistical tests</a></li>
<li class="chapter" data-level="24.2" data-path="statistical-analysis.html"><a href="statistical-analysis.html#causality"><i class="fa fa-check"></i><b>24.2</b> Causality</a></li>
<li class="chapter" data-level="24.3" data-path="statistical-analysis.html"><a href="statistical-analysis.html#anova"><i class="fa fa-check"></i><b>24.3</b> Anova</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="terms-and-notations.html"><a href="terms-and-notations.html"><i class="fa fa-check"></i><b>25</b> Terms and notations</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine learning, statistics, and optimization: A collection of intuitions</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Machine learning, statistics, and optimization: A collection of intuitions</h1>
<p class="author"><em>Reza Bonyadi, Ph.D.</em></p>
<p class="date"><em>2020-03-23</em></p>
</div>
<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<p><img src="images/title_page.jpg" width="250" height="375" alt="The geocompr book cover" align="right" style="margin: 0 1em 0 1em" /></p>
<p>I wrote my first machine learning (ML) project in the autumn of 2000, which was a characters hand-written recognition in the Pascal language, and I quite enjoyed the topic ever since. The field is growing astronomically fast these days and everyday I am learning something new. One reason behind such fast growth is that the top largest companies in the world, i.e., Microsoft, Google, Amazon, and Apple, all invest their largest R&amp;D budgets on this.</p>
<p>This collection (or as I call it, hyper-book) is meant to document and centralize the best links, descriptions, and materials in each topic I found for my learning (so, basically my notes in an organized way with links). The intention is not to re-write what has been written hundreds of times by very skilled authors, but to summarize methods, rank best pages/books which describe them, and refer to programming codes I found the best for that topic, if relevant. For each topic I provide my opinion and intuition on what it is, what are examples of it, and how to find more details. I keep the descriptions simple and to the point, with minimum mathematical equations, if possible.</p>
<p>The idea of this collection is not to undermine any Mathematical finding and theoretical background related to the fields reviewed here (I personally am a fan), rather, to pair those with intuitions and examples to make these topics more accessible for and larger audience. It is also important to notice the way this collection has been organized, machine learning, statistics, and optimization, is not ideal, as it is difficult to separate these topics completely. I agree that many algorithms in machine learning these days are âold newsâ in the field of statistics (e.g., linear regression), while some other algorithms may not have been possible to invent if statistics was going to be the main stream (e.g., deep neural networks). Topics like derivative-based optimization are so heavily involved in machine learning these days to an extent to which they owe their maturity to some extent. As it is clear, it is really difficult to claim if different parts of this collection are really different, however, the grouping has been taken place for the sake of cleanness and familiarity of the titles.</p>
<p>Each section in this book is tagged by one of the letters, I, C, or D, referring to whether the discussion in that section is going to be intuitive, based on the code, or deep mathematics. This would help the audience to pick the sections which they care about most, which makes the reading more effective and enjoyable.</p>

</div>



            </section>

          </div>
        </div>
      </div>

<a href="introduction.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
